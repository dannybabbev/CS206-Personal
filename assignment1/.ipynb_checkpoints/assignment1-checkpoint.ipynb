{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student Name: \n",
    "\n",
    "Student id: \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Dealing with data Pythonically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might find these packages useful. You may import any others you want!\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. The file `\"data/ads_dataset.tsv\"` uses tabs instead of commas to separate fields. Load the data set `\"data/ads_dataset.tsv\"` into a Python `pandas` data frame called `ads`. If you are using the `read_csv()` function you will need to know that `\"\\t\"` means tab when trying to set the delimeter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Write a Python function called `getDfSummary()` that does the following:\n",
    "- Takes as input a data frame\n",
    "- Creates a new data frame called `output_data` that:\n",
    "  - Consists of the output of the `pandas` function `describe()`. (*Hint: Check the `pandas` [(manual page)](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html) for this function if you want to learn more.*)\n",
    "  - The data frame `output_data` should have the original feature names from `input_data` as **rows**. (*Hint: Are they rows by default? If not, how could you make them rows?*)\n",
    "  - Adds a column called `spread` that is the result of subtracting the `min` from the `max`. (*Hint: What does the `describe()` function return? Do we have a column called `max` and `min`?*)\n",
    "- Returns the new `output_data` data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDfSummary(input_data):\n",
    "    output_data = ...\n",
    "    # Place your code here\n",
    "\n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. How long does it take for your `getDfSummary()` function to work on your `ads` data frame? Show us the results below.\n",
    "\n",
    "*Hint: `%timeit getDfSummary(ads)`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Show the output of the `getDfSummary()` function you created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Place your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Using the results returned from `getDfSummary()`, which fields, if any, have a spread of 1? Full credit will be given for a code based approach that prints out the correct field names. Partial credit will be given if you simply manually explore the results of `getDfSummary()`. Print each field name on a line by itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Place your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. For the fields that have a spread of 1, what percentage of records have the value of `1`? You may assume that if a field had a spread of 1 that it only has values 1 and 0.\n",
    "\n",
    "Full credit will be given for a code based approach that prints out the correct field names **and** their respective percentages. Partial credit will be given if you simply manually explore the results of `getDfSummary()`. (*Hint: Using the `pandas` function `.get_value()` may be useful if you happen to know the row and column name you want.*)\n",
    "\n",
    "Your results should look something like this:\n",
    "\n",
    "`The field` **`xxx`** `has` **`yyy`** `percent of its records set to 1.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2. Functions, loops and plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Write a function called `squared_less_100()` that takes a single number, squares it, and then returns the square minus 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_less_100(input_number):\n",
    "    output_number = ...\n",
    "    # Code here!\n",
    "    \n",
    "    return output_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Create three empty lists called `sl1_results`, `absolute_results`, `log_results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl1_results = ...\n",
    "absolute_results = ...\n",
    "log_results = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Create a list of integers from 1 to 20 (including both 1 and 20) called `original_set`. Loop through this list and apply your `squared_less_100()` function, the `numpy` function for finding absolute value, and the `numpy` natural log function. Store the result of each function by appending it the the initially empty lists you created in Part 4 Question 2. (*Hint: If you don't know what the `numpy` functions for absolute value or natural logs are, simply search online and it will be one of the first results. Although, you can probably guess what they would be!*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here!\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "    original_set = ...\n",
    "\n",
    "    for ...\n",
    "    # Code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Create a plot of your results. On the x-axis put `original_set`. Now, all within the **same plot** put a line for the `sl1_results`, a line for `absolute_results`, and a line for `log_results`. Don't forget to add a legend so that I know which line is for which set of results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Decision trees vs. Linear discriminant models\n",
    "What are the similarities and differences of decision trees and linear discriminant models? When might you prefer to use one over another? **This explanation should be around 1 paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For your hands-on excercise, I am going to ask you to build two different models and show me the impact of training/fitting them with different amounts of data. For this example we will be using the `data/cell2cell.csv` data.\n",
    "\n",
    "These historical data consist of 31,892 customers: 15,855 customers that churned (i.e., left the company) and 16,036 that did not churn. Here are the data set's 12 columns:\n",
    "\n",
    "```\n",
    "Col.  Var. Name  Var. Description\n",
    "----- ---------- --------------------------------------------------------------\n",
    "1     revenue    Mean monthly revenue in dollars\n",
    "2     outcalls   Mean number of outbound voice calls\n",
    "3     incalls    Mean number of inbound voice calls\n",
    "4     months     Months in Service\n",
    "5     eqpdays    Number of days the customer has had his/her current equipment\n",
    "6     webcap     Handset is web capable\n",
    "7     marryyes   Married (1=Yes; 0=No)\n",
    "8     travel     Has traveled to non-US country (1=Yes; 0=No)\n",
    "9     pcown      Owns a personal computer (1=Yes; 0=No)\n",
    "10    creditcd   Possesses a credit card (1=Yes; 0=No)\n",
    "11    retcalls   Number of calls previously made to retention team\n",
    "12    churndep   Did the customer churn (1=Yes; 0=No)\n",
    "```\n",
    "\n",
    "The first 11 columns are our attributes/features. The last column, `\"churndep\"`, is the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Now you should create a decision tree using entropy with no max depth and a logistic regression. For each of these models, assign 10% to 90% of the data to training (in increments of 10%) and the rest to test. For each training set, you need to fit both models and then get the accuracy on the remaining data used for test for both models. \n",
    "\n",
    "Then create a plot where the x-axis includes 0.10 to 0.90 (one tick for each training data percentage) and the y-axis indicates accuracy. Your plot should have two lines/curves on it: one for the decision tree and one for logistic regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Interpret the plot and what it is telling us. What is the relationship between the amount of training data and the model performance that is shown in the curves for the logistic regression model and the decision tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
