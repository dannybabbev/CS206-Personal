{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Mining\n",
    "## Practical 3 excercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Planning\n",
    "1\\. The owner of a shop selling products for kitchen renovations, her name is Lin, decides that she should extend the range of products she offers to also sell homeware products (e.g. decorations, baskets, glassware, pictures etc). Having had success using customer data to build predictive models to guide direct mail campaigns for special product offers, she considers that data mining could help her to identify a subset of customers who should be good prospects for the new set of products. Is Lin ready to solve this as a supervised learning problem? What would you suggest as the target variable? Be precise. Is there anything else that you would recommend that Lin do to achieve her business goal? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Evaluation Metrics\n",
    "Answer each of the following questions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. What are problems with using accuracy to evaluate the performance of a model? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Describe k-fold cross validation. What are some of it's advantages when compared to a simple, single hold-out data set. Are there any disadvantages you can think of? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data consists of a mail response data set from a direct marketing campaign. It is located in `data/mailing.csv`. Each record (row) refers to an individual who was targeted with a direct marketing offer. The offer was for the individual to make a charitable donation. \n",
    "\n",
    "The columns (features/attributes) are as follows:\n",
    "\n",
    "```\n",
    "Col.  Name      Description\n",
    "----- --------- ----------------------------------------------------------------\n",
    "1     income    household income\n",
    "2     Firstdate data assoc. with the first gift by this individual\n",
    "3     Lastdate  data associated with the most recent gift \n",
    "4     Amount    average amount by this individual over all periods (incl. zeros)\n",
    "5     rfaf2     frequency code\n",
    "6     rfaa2     donation amount code\n",
    "7     pepstrfl  flag indicating a star donator\n",
    "8     glast     amount of last gift\n",
    "9     gavr      amount of average gift\n",
    "10    class     one if they gave in this campaign and zero otherwise.\n",
    "```\n",
    "\n",
    "In this practical the goal is to build a model to predict if people will give to the charitable cause during the current campaign (this is the attribute `\"class\"` which has a value of 1 if they gave money and 0 if they did not)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First read the data in and put the target variable in `Y` and the features in `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read data using pandas\n",
    "data = pd.read_csv(\"data/mailing.csv\")\n",
    "\n",
    "# Split into X and Y\n",
    "X = data.drop(['class'], 1)\n",
    "Y = data['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling and Learning Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a decision tree (use entropy) and fit it and use it on **all** of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 0.9956460300658571\n"
     ]
    }
   ],
   "source": [
    "# Import decision trees and logistic regression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Import train, test, and evaluation functions\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create an object to learn the classifier (it is not fitted or learned at this stage)\n",
    "tree = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "\n",
    "# Fit the model\n",
    "tree.fit(X, Y)\n",
    "\n",
    "# Get prediction on all data\n",
    "Y_predicted = tree.predict(X)\n",
    "\n",
    "# Get the accuracy over the dataset and compare to the actual points\n",
    "accuracy = accuracy_score(Y_predicted, Y)\n",
    "\n",
    "# Print the accuracy\n",
    "print (\"The accuracy is \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's high accuracy... It may be overfitting to the data because no training data was used - test if the model performs on unseen data not used in training.\n",
    "\n",
    "Create train and test sets of `X` and `Y` where we assign 70% of our data to training (ie 100 - 30 % for test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit model just to training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 0.9012410053185942\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tree = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "\n",
    "# Fit the tree on the training data\n",
    "tree.fit(X_train, Y_train)\n",
    "\n",
    "# Get a prediction from the tree on the test data\n",
    "Y_test_predicted = tree.predict(X_test)\n",
    "\n",
    "# Get the accuracy of this prediction\n",
    "accuracy = accuracy_score(Y_test_predicted, Y_test)\n",
    "\n",
    "# Print the accuracy\n",
    "print (\"The accuracy is \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Big difference - almost 10 percent. Which tree would you trust more to make predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work in your project teams to answer this question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the following code as a template try to measure the performance with different training data set sizes for the decision tree and a logistic regression model. \n",
    "\n",
    "Check the accuracy with percentages from 20% test data to 80% test data. \n",
    "\n",
    "Generate a plot that has percentages on the x-axis and accuracies on the y-axis. This is called a **learning curve**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib for plotting\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-21-650fc3159d54>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-21-650fc3159d54>\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=???)\u001b[0m\n\u001b[1;37m                                                                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Here are some percentages to get you started. Feel free to try more!\n",
    "test_percentages = [0.80, 0.60, 0.40, 0.20]\n",
    "accuracies = []\n",
    "\n",
    "for training_percentage in training_percentages:\n",
    "    # Here I am training on 70%. What should I change this to so that I can try many percentages?\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=???)\n",
    "\n",
    "    # This will create an empty logistic regression\n",
    "    logistic = LogisticRegression()\n",
    "    \n",
    "    # This will fit/train your logistic regression\n",
    "    logistic.fit(...)\n",
    "    \n",
    "    # This will get predictions\n",
    "    Y_test_predicted = logistic.predict(...)\n",
    "    \n",
    "    # With these predictions we can get an accuracy. Where should we store this accuracy?\n",
    "    accuracy_score(..., ...)\n",
    "\n",
    "# We want to plot our results. What list should we use for the x-axis? What about the y-axis?\n",
    "plt.plot(???,???)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a fitting curve by controlling the model complexity - tree depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-39ef5dbf911d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# We want to plot our results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Max depth (model complexity)\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Let's fit our training data size to 80%\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.80)\n",
    "\n",
    "# Let's try different max depths for a decision tree\n",
    "max_depths = range(1, 10)\n",
    "accuracies = []\n",
    "\n",
    "for max_depth in max_depths:\n",
    "    # This will create an empty decision tree at a specified max depth\n",
    "    tree = DecisionTreeClassifier(max_depth=max_depth)\n",
    "    \n",
    "    # This will fit/train your tree\n",
    "    tree.fit(X_train, Y_train)\n",
    "    \n",
    "    # This will get accuracy and keep track of it\n",
    "    Y_test_predicted = tree.predict(X_test)\n",
    "    accuracies.append(accuracy_score(Y_test_predicted, Y_test))\n",
    "\n",
    "# We want to plot our results\n",
    "plt.plot(max_depths, accuracies)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Max depth (model complexity)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
